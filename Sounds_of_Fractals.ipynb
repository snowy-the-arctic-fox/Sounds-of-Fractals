{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEz4PnlYyKV5QcMGqN2U9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snowy-the-arctic-fox/Sounds-of-Fractals/blob/main/Sounds_of_Fractals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sounds of Fractals\n",
        "In the [previous code](https://github.com/snowy-the-arctic-fox/Fractal-Generator/tree/main), generated a fractal apon a few values/inputs from the user. These inputs consists of `Julian Constant 1`, `Julian Constant 2`, `Division Factor`. in this code, the fractal is turned into an audio file! A spectrogram was generated to display the frequency content of an audio signal over time. The `plt.specgram()` function from the matplotlib library was used to calculate the spectrogram, which represents the magnitude of the Fourier transform of overlapping short-time segments of the audio signal. The frequency content of each segment is displayed as a vertical bar for each frequency bin, while time progresses horizontally. \n",
        "\n",
        "The logarithmic scale for frequencies was set up by applying the `np.log10()` function to the frequency bins, which helps to better visualize the distribution of frequency components. A colormap was used to assign a different color to each frequency bin, with the color intensity representing the magnitude of each frequency component. \n",
        "\n",
        "However, a warning message appeared indicating that there were \"invalid value encountered in log10\". This may be due to the presence of zero or negative values in the frequency bins, which cause the logarithm function to return an undefined value. To avoid this issue, a small constant value was added to the frequency bins before applying the `np.log10()` function."
      ],
      "metadata": {
        "id": "lxzt2Hx_Si-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ66ipL1JCoA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install { vertical-output: true }\n",
        "!pip install numpy matplotlib librosa pydsm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initial Julia Definition\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_julia(width, height, max_iter, c):\n",
        "    x = np.linspace(-2.5, 1.5, width)\n",
        "    y = np.linspace(-2, 2, height)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = X + 1j * Y\n",
        "\n",
        "    fractal = np.zeros(Z.shape, dtype=int)\n",
        "    z = Z.copy()\n",
        "    \n",
        "    for i in range(max_iter):\n",
        "        mask = np.abs(z) < 2\n",
        "        z[mask] = z[mask] ** 2 + c\n",
        "        fractal += mask\n",
        "    \n",
        "    return fractal\n",
        "\n",
        "# Set the dimensions of the fractal image\n",
        "width = 640\n",
        "height = 480"
      ],
      "metadata": {
        "id": "xd7hGOXYJEsQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fractal Generator\n",
        "# Set the maximum number of iterations\n",
        "max_iter = int(input(\"Max iterations: \"))\n",
        "\n",
        "# Get the user inputs for the Julia set numbers\n",
        "j1 = float(input(\"Julia constant factor 1: \"))\n",
        "j2 = float(input(\"Julia constant factor 2: \"))\n",
        "div = float(input(\"Division Factor: \"))\n",
        "\n",
        "# Set the constant 'c' for the Julia set\n",
        "c = (j1 + j2) / div\n",
        "\n",
        "# Generate the fractal\n",
        "fractal = generate_julia(width, height, max_iter, c)\n"
      ],
      "metadata": {
        "id": "cd8ehUzBJHf-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fractal Out\n",
        "# Display the fractal image\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(fractal, cmap='hot', extent=(-2.5, 1.5, -2, 2))\n",
        "plt.title('Julia Set Fractal')\n",
        "plt.xlabel('Re(c)')\n",
        "plt.ylabel('Im(c)')\n",
        "plt.colorbar(label='Iterations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1lRYIgAgKgRr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Audio\n",
        "# Generate the audio signal\n",
        "import numpy as np\n",
        "\n",
        "# Set the audio parameters\n",
        "duration = 5  # Duration of the audio in seconds\n",
        "sample_rate = 44100  # Sample rate (number of samples per second)\n",
        "\n",
        "# Generate a random audio signal\n",
        "t = np.linspace(0, duration, duration * sample_rate, endpoint=False)\n",
        "audio = np.random.uniform(-1, 1, len(t))\n",
        "\n",
        "# Normalize the audio signal\n",
        "normalized_audio = audio / np.max(np.abs(audio))\n",
        "scaling_factor = 0.9 * (np.iinfo(np.int16).max)\n",
        "audio = (normalized_audio * scaling_factor).astype(np.int16)\n",
        "\n",
        "# Save the audio signal as a WAV file\n",
        "from scipy.io import wavfile\n",
        "\n",
        "output_file = 'fractal_audio.wav'\n",
        "\n",
        "# Normalize the audio signal\n",
        "normalized_audio = audio / np.max(np.abs(audio))\n",
        "scaling_factor = 0.9 * (np.iinfo(np.int16).max)\n",
        "audio = (normalized_audio * scaling_factor).astype(np.int16)\n",
        "\n",
        "# Save the audio signal as a WAV file\n",
        "wavfile.write(output_file, sample_rate, audio)\n"
      ],
      "metadata": {
        "id": "s5JhGht-KihS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download and Load Audio\n",
        "from IPython.display import Audio\n",
        "from google.colab import files\n",
        "\n",
        "# Download the audio file\n",
        "files.download('fractal_audio.wav')\n",
        "\n",
        "audio_file = 'fractal_audio.wav'\n",
        "\n",
        "# Display the audio widget\n",
        "Audio(audio_file)"
      ],
      "metadata": {
        "id": "2Fo5tGN1L0R7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Waterfall Visualization (log)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the spectrogram of the audio signal\n",
        "_, _, _, spectrogram = plt.specgram(audio, Fs=sample_rate)\n",
        "\n",
        "# Get the spectrogram data from the AxesImage object\n",
        "spectrogram_data = spectrogram.get_array()\n",
        "\n",
        "# Get the number of frequency bins and time steps from the spectrogram data\n",
        "num_freq_bins = spectrogram_data.shape[0]\n",
        "num_time_steps = spectrogram_data.shape[1]\n",
        "\n",
        "# Set up the logarithmic scale for frequencies\n",
        "freqs = np.fft.fftfreq(num_freq_bins, d=1/sample_rate)[1:]\n",
        "log_frequencies = np.log10(np.where(freqs > 0, freqs, 1e-9))\n",
        "\n",
        "# Set up the colormap\n",
        "cmap = plt.get_cmap('jet')\n",
        "\n",
        "# Display the waterfall plot of the audio signal with color-coded frequencies\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.imshow(log_frequencies.reshape(-1, 1), extent=[0, num_time_steps, 0, 1], aspect='auto', cmap=cmap, origin='lower')"
      ],
      "metadata": {
        "id": "x3vr3-UlKnVQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}